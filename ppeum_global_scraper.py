"""
ì¨ ê¸€ë¡œë²Œ í´ë¦¬ë‹‰ ì „ìš© ìŠ¤í¬ë˜í¼
"""
import asyncio
import os
from datetime import datetime
from typing import List

from src.config.site_configs import site_config_manager
from src.scrapers.spa_scraper import ConfigurableScraper
from src.utils.llm_extractor import LLMTreatmentExtractor
from src.models.schemas import ProductItem


class PpeumGlobalScraper:
    """ì¨ ê¸€ë¡œë²Œ í´ë¦¬ë‹‰ ì „ìš© ìŠ¤í¬ë˜í¼"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.llm_extractor = LLMTreatmentExtractor(api_key)
        self.config = site_config_manager.create_ppeum_global_config()

    async def scrape_treatments(self) -> List[ProductItem]:
        """ì¨ ê¸€ë¡œë²Œ í´ë¦¬ë‹‰ì˜ ì‹œìˆ  ì •ë³´ ìŠ¤í¬ë˜í•‘"""
        print(f"ğŸš€ ì¨ ê¸€ë¡œë²Œ í´ë¦¬ë‹‰ ìŠ¤í¬ë˜í•‘ ì‹œì‘...")
        print(f"ğŸ“‹ ì„¤ì •:")
        print(f"   - ì†ŒìŠ¤ íƒ€ì…: {self.config.source_type}")
        print(f"   - ëŒ€ìƒ URL: {self.config.static_urls[0] if self.config.static_urls else self.config.base_url}")
        print(f"   - SPA ëª¨ë“œ: {self.config.spa_config.max_interactions}ë²ˆ ìµœëŒ€ ìƒí˜¸ì‘ìš©")

        try:
            scraper = ConfigurableScraper(self.config, self.llm_extractor)
            products = await scraper.scrape_by_config()

            print(f"âœ… ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!")
            print(f"ğŸ“¦ ë°œê²¬ëœ ìƒí’ˆ: {len(products)}ê°œ")

            if products:
                # ì‹œìˆ  í†µê³„
                total_treatments = sum(len(product.treatments) for product in products)
                print(f"ğŸ’‰ ì´ ì‹œìˆ  ìˆ˜: {total_treatments}ê°œ")

                # ìƒ˜í”Œ ìƒí’ˆ ì •ë³´ ì¶œë ¥
                print(f"\nğŸ“„ ìƒ˜í”Œ ìƒí’ˆë“¤:")
                for i, product in enumerate(products[:3], 1):
                    print(f"   {i}. {product.product_name}")
                    print(f"      í´ë¦¬ë‹‰: {product.clinic_name}")
                    if product.product_event_price:
                        print(f"      ê°€ê²©: {product.product_event_price:,}ì›")
                    print(f"      ì‹œìˆ  ìˆ˜: {len(product.treatments)}ê°œ")

            return products

        except Exception as e:
            print(f"âŒ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}")
            return []

    def save_results(self, products: List[ProductItem], suffix: str = "") -> str:
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not products:
            print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ""

        os.makedirs("data/raw", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"data/raw/ppeum_global_treatments_{timestamp}{suffix}.json"

        import json
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(
                [product.model_dump() for product in products],
                f,
                ensure_ascii=False,
                indent=2,
                default=str
            )

        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
        return filename


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # Anthropic API í‚¤ í™•ì¸
    api_key = os.getenv("ANTHROPIC_AUTH_TOKEN")
    if not api_key:
        print("âŒ ANTHROPIC_AUTH_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        print("1. .env íŒŒì¼ì— ANTHROPIC_AUTH_TOKEN=your-api-key-here")
        print("2. export ANTHROPIC_AUTH_TOKEN='your-api-key-here'")
        return

    # ìŠ¤í¬ë˜í¼ ì‹¤í–‰
    scraper = PpeumGlobalScraper(api_key)
    products = await scraper.scrape_treatments()

    # ê²°ê³¼ ì €ì¥
    if products:
        scraper.save_results(products)
    else:
        print("ğŸ“­ ìŠ¤í¬ë˜í•‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main())