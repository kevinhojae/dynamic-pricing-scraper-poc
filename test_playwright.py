#!/usr/bin/env python3
"""
Playwrightë¥¼ ì‚¬ìš©í•´ì„œ JavaScript ë Œë”ë§ í›„ ì½˜í…ì¸  í™•ì¸
"""

import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import re

async def test_playwright_content():
    """Playwrightë¡œ JavaScript ë Œë”ë§ í›„ ì½˜í…ì¸  í™•ì¸"""

    test_url = "https://xenia.clinic/ko/products/8a2a54b8-0eaa-4d28-945b-2c76cb98eb9b"

    async with async_playwright() as p:
        print(f"ğŸš€ Testing Playwright with: {test_url}")

        # ë¸Œë¼ìš°ì € ì‹¤í–‰ (headless ëª¨ë“œ)
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            viewport={'width': 1920, 'height': 1080}
        )
        page = await context.new_page()

        try:
            # í˜ì´ì§€ë¡œ ì´ë™
            print("â³ Loading page...")
            await page.goto(test_url, wait_until='domcontentloaded', timeout=30000)

            # JavaScript ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°
            print("â³ Waiting for content to load...")
            await page.wait_for_timeout(3000)  # 3ì´ˆ ê¸°ë³¸ ëŒ€ê¸°

            # íŠ¹ì • ì½˜í…ì¸ ê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            try:
                # ì¼ë°˜ì ì¸ ì½˜í…ì¸  ìš”ì†Œë“¤ì„ ê¸°ë‹¤ë¦¼
                await page.wait_for_selector('main, .content, .product, h1, h2, p', timeout=10000)
                print("âœ… Content elements detected")
            except:
                print("âš ï¸  No specific content elements found, proceeding...")

            # ì¶”ê°€ ëŒ€ê¸° (ë™ì  ì½˜í…ì¸ ë¥¼ ìœ„í•´)
            await page.wait_for_timeout(2000)

            # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            try:
                await page.wait_for_load_state('networkidle', timeout=5000)
                print("âœ… Network requests completed")
            except:
                print("âš ï¸  Network still active, proceeding...")

            # í˜ì´ì§€ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°
            content = await page.content()
            print(f"ğŸ“Š Playwright HTML Length: {len(content)} characters")

            # ì¼ë¶€ HTML ì¶œë ¥
            print(f"\nğŸ“ Playwright HTML Sample (first 1000 chars):")
            print("-" * 50)
            print(content[:1000])
            print("-" * 50)

            # BeautifulSoupìœ¼ë¡œ íŒŒì‹± (ì‹¤ì œ LLM extractorì™€ ë™ì¼í•œ ë°©ì‹)
            soup = BeautifulSoup(content, "html.parser")

            # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±° (ì‹¤ì œ ì½”ë“œì™€ ë™ì¼)
            for tag in soup(["script", "style", "nav", "footer", "header"]):
                tag.decompose()

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_content = soup.get_text(separator=" ", strip=True)
            print(f"ğŸ“Š Playwright Extracted Text Length: {len(text_content)} characters")

            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ
            print(f"\nğŸ“ Playwright Extracted Text Sample (first 2000 chars):")
            print("-" * 50)
            print(text_content[:2000])
            print("-" * 50)

            # ì‹œìˆ  ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
            treatment_keywords = [
                'ì‹œìˆ ', 'ì¹˜ë£Œ', 'ì„œë¹„ìŠ¤', 'ê°€ê²©', 'ì›', 'ìƒ·', 'cc', 'ë³´í†¡ìŠ¤', 'í•„ëŸ¬',
                'ë ˆì´ì €', 'ìŠˆë§í¬', 'ìš¸ì„ë¼', 'ë¦¬í”„íŒ…', 'ì£¼ì‚¬', 'í”„ë¡œê·¸ë¨', 'ì˜ˆì•½',
                'ì´ë²¤íŠ¸', 'í• ì¸', 'ì •ìƒê°€', 'íŠ¹ê°€'
            ]

            found_keywords = []
            for keyword in treatment_keywords:
                if keyword in text_content:
                    count = text_content.count(keyword)
                    found_keywords.append(f"{keyword}({count}íšŒ)")

            print(f"\nğŸ” Playwright Found Treatment Keywords: {', '.join(found_keywords) if found_keywords else 'ì—†ìŒ'}")

            # ê°€ê²© íŒ¨í„´ ê²€ìƒ‰
            price_patterns = [
                r'\d+,?\d+ì›',
                r'\d+,?\d+\s*ì›',
                r'â‚©\s*\d+,?\d+',
                r'\d+ë§Œì›',
                r'\d{1,3}(?:,\d{3})*ì›',
            ]

            found_prices = []
            for pattern in price_patterns:
                matches = re.findall(pattern, text_content)
                found_prices.extend(matches)

            print(f"ğŸ’° Playwright Found Price Patterns: {found_prices[:15] if found_prices else 'ì—†ìŒ'}")

            # HTML êµ¬ì¡° ë¶„ì„
            print(f"\nğŸ—ï¸  Playwright HTML Structure Analysis:")
            print(f"- <title>: {soup.title.string if soup.title else 'None'}")
            print(f"- <h1> tags: {len(soup.find_all('h1'))}")
            print(f"- <h2> tags: {len(soup.find_all('h2'))}")
            print(f"- <h3> tags: {len(soup.find_all('h3'))}")
            print(f"- <p> tags: {len(soup.find_all('p'))}")
            print(f"- <div> tags: {len(soup.find_all('div'))}")
            print(f"- <button> tags: {len(soup.find_all('button'))}")
            print(f"- <span> tags: {len(soup.find_all('span'))}")

            # íŠ¹ì • í´ë˜ìŠ¤ë‚˜ IDë¡œ ì½˜í…ì¸  ì°¾ê¸°
            potential_selectors = [
                ".product", ".treatment", ".service", ".content", ".main", ".container",
                "#product", "#treatment", "#service", "#content", "#main",
                "[class*='product']", "[class*='treatment']", "[class*='service']",
                "[class*='price']", "[class*='cost']"
            ]

            print(f"\nğŸ¯ Content Element Search:")
            for selector in potential_selectors:
                try:
                    elements = soup.select(selector)
                    if elements:
                        print(f"  - {selector}: {len(elements)} elements found")
                        for i, element in enumerate(elements[:2]):  # ì²˜ìŒ 2ê°œë§Œ í™•ì¸
                            element_text = element.get_text(strip=True)
                            if element_text and len(element_text) > 10:
                                print(f"    [{i+1}] {element_text[:150]}...")
                except Exception as e:
                    continue

            # DOMì—ì„œ ì§ì ‘ ë°ì´í„° ì°¾ê¸° (React state ë“±)
            print(f"\nğŸ” JavaScript Data Search:")
            try:
                # í˜ì´ì§€ì—ì„œ JavaScript ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ì°¾ê¸°
                js_data = await page.evaluate("""
                    () => {
                        // React DevTools ë°ì´í„° ì°¾ê¸°
                        const results = {};

                        // window ê°ì²´ì—ì„œ ë°ì´í„° ì°¾ê¸°
                        if (window.__INITIAL_STATE__) results.initial_state = window.__INITIAL_STATE__;
                        if (window.__PRELOADED_STATE__) results.preloaded_state = window.__PRELOADED_STATE__;
                        if (window.__NEXT_DATA__) results.next_data = window.__NEXT_DATA__;

                        // React Fiber ë°ì´í„° ì°¾ê¸°
                        const reactFiber = document.querySelector('[data-reactroot]');
                        if (reactFiber && reactFiber._reactInternalFiber) {
                            results.react_fiber = 'found';
                        }

                        // ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ë°ì´í„°
                        if (localStorage.length > 0) {
                            results.localStorage_keys = Object.keys(localStorage);
                        }

                        // ì„¸ì…˜ ìŠ¤í† ë¦¬ì§€ ë°ì´í„°
                        if (sessionStorage.length > 0) {
                            results.sessionStorage_keys = Object.keys(sessionStorage);
                        }

                        return results;
                    }
                """)

                if js_data:
                    print(f"   JavaScript Data Found: {list(js_data.keys())}")
                    if 'next_data' in js_data:
                        print(f"   Next.js Data Keys: {list(js_data['next_data'].keys()) if isinstance(js_data['next_data'], dict) else 'Not dict'}")
                else:
                    print("   No JavaScript data found")

            except Exception as e:
                print(f"   JavaScript evaluation error: {str(e)}")

            # ê²°ë¡  íŒì •
            success_criteria = [
                len(text_content) > 500,  # ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ ê¸¸ì´
                len(found_keywords) > 3,  # ì‹œìˆ  ê´€ë ¨ í‚¤ì›Œë“œ ë°œê²¬
                len(found_prices) > 0,    # ê°€ê²© ì •ë³´ ë°œê²¬
            ]

            success_count = sum(success_criteria)
            print(f"\nğŸ“Š Success Criteria Met: {success_count}/3")

            if success_count >= 2:
                print("âœ… SUCCESS: Playwright successfully extracted meaningful content!")
                # í…ìŠ¤íŠ¸ê°€ 30000ì ì œí•œ í™•ì¸
                if len(text_content) > 30000:
                    final_text = text_content[:30000] + "..."
                    print(f"âš ï¸  Text will be truncated from {len(text_content)} to 30000 chars for LLM")
                else:
                    final_text = text_content
                    print(f"âœ… Text within LLM limit: {len(text_content)} chars")

                return True, final_text
            else:
                print("âŒ FAILURE: Content extraction still insufficient")
                return False, text_content

        except Exception as e:
            print(f"âŒ Playwright test failed: {str(e)}")
            return False, ""

        finally:
            await browser.close()

if __name__ == "__main__":
    success, content = asyncio.run(test_playwright_content())
    if success:
        print(f"\nğŸ‰ Ready to integrate Playwright into LLM extraction pipeline!")
    else:
        print(f"\nâš ï¸  Need to investigate further or try different approach")